{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2pHUg1QwZQb+BKDMHwYfJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoizAhmed2517/Deep_Learning_Projects/blob/main/Food_Classification_Using_Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning - Food Vision App"
      ],
      "metadata": {
        "id": "r-Atdl0Xh5jy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiwCFvxliYB_",
        "outputId": "c9c4c71f-5adc-46ac-8a82-08356752920e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-23 18:32:27--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.69.128, 173.194.79.128, 108.177.119.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.69.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M  40.0MB/s    in 4.8s    \n",
            "\n",
            "2022-11-23 18:32:32 (33.6 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zipref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zipref.extractall()\n",
        "zipref.close()"
      ],
      "metadata": {
        "id": "mqK1IizTiZlI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAkwkxiri8YM",
        "outputId": "76885c64-0dac-4687-e340-b0d9f90ff6f5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Activation, MaxPool2D"
      ],
      "metadata": {
        "id": "rN_eMlsRlWFS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               batch_size=BATCH_SIZE)\n",
        "\n",
        "test_data = train_datagen.flow_from_directory(test_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               class_mode=\"categorical\",\n",
        "                                               batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndGWuVVSmKoV",
        "outputId": "94a0f4bf-1437-42db-fa89-ec1133b976a0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 images belonging to 10 classes.\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting our callbacks (things to run whilst our model trains)\n",
        "\n",
        "Callbacks are extra fucntionality you can add to your models to be performed during or after training. Some of the most popular callbacks are:\n",
        "\n",
        "* Tracking experiments with the TensorBoard callback\n",
        "* Model checkpoint with the ModelCheckPoint callback\n",
        "* Using Earlystopping technique as callback"
      ],
      "metadata": {
        "id": "P2_han_bmFv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a function for settingUp Tensorboard callback\n",
        "\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-$H%M%S\")\n",
        "  tensorboar_callback = tf.keras.callbacks.TensorBoard(log_dir)\n",
        "  print(f\"Saving Tensorboard log files to:  {log_dir}\")\n",
        "  return tensorboar_callback"
      ],
      "metadata": {
        "id": "dONNOzUewvLQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Browsing the tensorflow HUb page and sorting for image classification\n",
        "# Using following two models in contrast with each other\n",
        "\n",
        "# 1. ImageNet/Resenet-V2-50/feature vector :https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\n",
        "# 2. EfficientNet/B0/feature Vector :https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1"
      ],
      "metadata": {
        "id": "iWAMUSy00KRy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_url = \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "oYUlesxb7XQ5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# Creating model builder function\n",
        "\n",
        "def create_model(model_url, num_classes=10):\n",
        "  \"\"\"\n",
        "  Takes a Tensorfloe HUB URL and creates a Keras Sequential mode with it.\n",
        "\n",
        "  ArgsL\n",
        "    model_url (Str): A tensorflow HUB Feature extraction URL\n",
        "    num_classes (int): NUmber of output neuron in the output layer\n",
        "      should be equal to number of target classes, default 10\n",
        "\n",
        "  Returns:\n",
        "    An uncompile keras sequential model with model_url as feature extractor layer and Dense output layer with num_classes output neuron.\n",
        "  \n",
        "  \"\"\"\n",
        "\n",
        "  feature_exctractor_layer = hub.KerasLayer(model_url, \n",
        "                                            trainable=False,  # Freeze the already learned pattern \n",
        "                                            name=\"feature_extraction_layer\",\n",
        "                                            input_shape=IMAGE_SHAPE+(3,)) \n",
        "  \n",
        "  model = tf.keras.Sequential([\n",
        "      feature_exctractor_layer,\n",
        "      Dense(num_classes, activation=\"softmax\", name=\"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model\n",
        "  \n"
      ],
      "metadata": {
        "id": "zojEHt7H7wDM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating ResNet TensorFlow HUB Feature Extraction mdoel"
      ],
      "metadata": {
        "id": "znipHSKp9_EZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data.num_classes)"
      ],
      "metadata": {
        "id": "AKZez-xp-E32"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                     optimizer=Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "dHr9LcED-f1f"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resenet_history = resnet_model.fit(train_data,\n",
        "                 epochs=5,\n",
        "                 steps_per_epoch=len(train_data),\n",
        "                 validation_data=test_data,\n",
        "                 validation_steps=len(test_data),\n",
        "                 callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                        experiment_name=\"resnet50V2\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZQsSek5_KaL",
        "outputId": "c3ea5de9-5bb8-423b-b0ae-b612ad8aec11"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Tensorboard log files to:  tensorflow_hub/resnet50V2/20221123-$H4352\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 18s 749ms/step - loss: 0.2443 - accuracy: 0.9573 - val_loss: 0.6340 - val_accuracy: 0.7900\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 17s 725ms/step - loss: 0.2035 - accuracy: 0.9773 - val_loss: 0.6388 - val_accuracy: 0.7932\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 17s 748ms/step - loss: 0.1738 - accuracy: 0.9827 - val_loss: 0.6232 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 17s 716ms/step - loss: 0.1484 - accuracy: 0.9933 - val_loss: 0.6266 - val_accuracy: 0.7948\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 17s 719ms/step - loss: 0.1300 - accuracy: 0.9960 - val_loss: 0.6289 - val_accuracy: 0.7920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FIhwkTAU_qI3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}