{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aqNiisVDERUpKkweLmDnKg2ViZbqTZkU",
      "authorship_tag": "ABX9TyOBQ9uJuJY4m4ClqivsO27U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MoizAhmed2517/Deep_Learning_Projects/blob/main/Polyp_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Polyp Detection - Using YOLOv5"
      ],
      "metadata": {
        "id": "EC_3m3oMeUUz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "from functools import reduce\n",
        "from xml.etree import ElementTree as et\n",
        "import zipfile \n",
        "from google.colab import drive\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from shutil import move"
      ],
      "metadata": {
        "id": "xcPmZkF1eXWe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Polyp Detection\")"
      ],
      "metadata": {
        "id": "JpyDzOsXe0yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VieJOWp2bbFU",
        "outputId": "86a7f62b-6ba8-4466-b1f3-0ebaa271db1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Polyp Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT6936VEbc03",
        "outputId": "2dbabacf-f366-41c8-879d-9a53120ea612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dataset.zip  'Polyp Detection.ipynb'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWlnqaafbhbL",
        "outputId": "3e6b023b-d6a2-42d9-a131-9b501a2a2a64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14887, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 14887 (delta 0), reused 0 (delta 0), pack-reused 14882\u001b[K\n",
            "Receiving objects: 100% (14887/14887), 13.86 MiB | 8.63 MiB/s, done.\n",
            "Resolving deltas: 100% (10246/10246), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Polyp Detection/dataset.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "Fc5MO65rbz__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/drive/MyDrive/Polyp Detection/dataset'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hQ6Ybg0Amd-",
        "outputId": "d969a514-d7d5-4137-a686-f87147f1bc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation - Reading XML Files"
      ],
      "metadata": {
        "id": "X7ciNrDHfjE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xml_lst = glob(\"/content/drive/MyDrive/Polyp Detection/dataset/*.xml\")"
      ],
      "metadata": {
        "id": "L2cqqpbNfsZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xml_lst[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5JDx-9Vg5gE",
        "outputId": "11aff126-2343-44cb-a278-dd49dda2ad80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/Polyp Detection/dataset/1.xml',\n",
              " '/content/drive/MyDrive/Polyp Detection/dataset/10.xml',\n",
              " '/content/drive/MyDrive/Polyp Detection/dataset/100.xml',\n",
              " '/content/drive/MyDrive/Polyp Detection/dataset/1000.xml',\n",
              " '/content/drive/MyDrive/Polyp Detection/dataset/101.xml']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree = et.parse(xml_lst[1])\n",
        "root = tree.getroot()"
      ],
      "metadata": {
        "id": "HrtwlZSZhAoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for child in root:\n",
        "  print(child.tag, child.attrib)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P6Cn2ZXhU1_",
        "outputId": "d75037b8-8ec4-4193-869d-19611d602ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "folder {}\n",
            "filename {}\n",
            "path {}\n",
            "source {}\n",
            "size {}\n",
            "object {}\n",
            "object {}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for object_xml in root.findall('object'):\n",
        "  name = object_xml.find('name').text\n",
        "  xmin = object_xml.find('bndbox/xmin').text\n",
        "  ymin = object_xml.find('bndbox/ymin').text\n",
        "  xmax = object_xml.find('bndbox/xmax').text\n",
        "  ymax = object_xml.find('bndbox/ymax').text\n",
        "  print(name, xmin, xmax, ymin, ymax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DlT9J-YYhYWJ",
        "outputId": "278f9793-9aa8-4196-b3ac-9c246e00cb97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polyp 270 362 247 391\n",
            "polyp 45 359 209 446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = root.find('filename').text\n",
        "filename"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "d9HkJ67Xg8o_",
        "outputId": "437f8e1d-4078-4e9e-83e9-15facfb05ef3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'10.jpg'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "width = root.find('size/width').text\n",
        "height = root.find('size/height').text\n",
        "\n",
        "print(width, height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C96cjQ-3hicz",
        "outputId": "15e0738b-f425-4062-9eaa-d9234d22b5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "611 530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Making final helper function for parsing XML files & making their list and converting into dataframe for furthur use."
      ],
      "metadata": {
        "id": "mi4iZSNThmpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xml_parser(filename):\n",
        "    tree = et.parse(filename)\n",
        "    root = tree.getroot()\n",
        "    filename = root.find('filename').text\n",
        "    width = root.find('size/width').text\n",
        "    height = root.find('size/height').text\n",
        "    parser = []\n",
        "\n",
        "    for object_xml in root.findall('object'):\n",
        "      name = object_xml.find('name').text\n",
        "      xmin = object_xml.find('bndbox/xmin').text\n",
        "      ymin = object_xml.find('bndbox/ymin').text\n",
        "      xmax = object_xml.find('bndbox/xmax').text\n",
        "      ymax = object_xml.find('bndbox/ymax').text\n",
        "      parser.append([filename, width, height, name, xmin, xmax, ymin, ymax])\n",
        "\n",
        "    return parser"
      ],
      "metadata": {
        "id": "daI6I34Aho5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xml_parser(xml_lst[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ-j2KVAhuHg",
        "outputId": "ff67051e-5841-4b28-ffeb-c9e86ae04684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['10.jpg', '611', '530', 'polyp', '270', '362', '247', '391'],\n",
              " ['10.jpg', '611', '530', 'polyp', '45', '359', '209', '446']]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xml_parser(xml_lst[100])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4RlU2adhv14",
        "outputId": "6db750a5-01b3-4dab-d532-f377a4fea7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['189.jpg', '543', '528', 'polyp', '215', '315', '224', '328']]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_all_xml_files = list(map(xml_parser, xml_lst))"
      ],
      "metadata": {
        "id": "FqxwAwdLhyd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = reduce(lambda x,y : x+y, parsed_all_xml_files)\n",
        "df = pd.DataFrame(data, columns=['filename', 'width', 'height', 'name', 'xmin', 'xmax', 'ymin', 'ymax'])"
      ],
      "metadata": {
        "id": "C1OsH1eQh5R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6tWBTbCJh-xE",
        "outputId": "ed5cd2b3-ccab-47b9-a524-722269aa2baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  filename width height   name xmin xmax ymin ymax\n",
              "0    1.jpg   619    529  polyp  243  427   19  142\n",
              "1    1.jpg   619    529  polyp  187  256  224  347\n",
              "2    1.jpg   619    529  polyp  345  412  159  267\n",
              "3    1.jpg   619    529  polyp  229  321  303  416\n",
              "4    1.jpg   619    529  polyp  340  382  407  459"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68ef26e4-31bd-45c9-a3d9-64fbc4e7b330\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>name</th>\n",
              "      <th>xmin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymin</th>\n",
              "      <th>ymax</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>243</td>\n",
              "      <td>427</td>\n",
              "      <td>19</td>\n",
              "      <td>142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>187</td>\n",
              "      <td>256</td>\n",
              "      <td>224</td>\n",
              "      <td>347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>345</td>\n",
              "      <td>412</td>\n",
              "      <td>159</td>\n",
              "      <td>267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>229</td>\n",
              "      <td>321</td>\n",
              "      <td>303</td>\n",
              "      <td>416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>340</td>\n",
              "      <td>382</td>\n",
              "      <td>407</td>\n",
              "      <td>459</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68ef26e4-31bd-45c9-a3d9-64fbc4e7b330')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-68ef26e4-31bd-45c9-a3d9-64fbc4e7b330 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-68ef26e4-31bd-45c9-a3d9-64fbc4e7b330');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmoslsbBiAIw",
        "outputId": "d9375870-6101-4b96-b357-30cd5f955412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['name'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEnDLtaAiKAZ",
        "outputId": "865c6de3-2c88-477b-e950-d76fb0fe3181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "polyp    1460\n",
              "Name: name, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbYGWaTnidk3",
        "outputId": "d418361f-6cd4-4d0e-d820-95a474ad477d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   filename  1460 non-null   object\n",
            " 1   width     1460 non-null   object\n",
            " 2   height    1460 non-null   object\n",
            " 3   name      1460 non-null   object\n",
            " 4   xmin      1460 non-null   object\n",
            " 5   xmax      1460 non-null   object\n",
            " 6   ymin      1460 non-null   object\n",
            " 7   ymax      1460 non-null   object\n",
            "dtypes: object(8)\n",
            "memory usage: 91.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated = df.copy()\n",
        "df_updated['width'] = df_updated['width'].astype(\"int64\")\n",
        "df_updated['height'] = df_updated['height'].astype(\"int64\")\n",
        "df_updated['xmin'] = df_updated['xmin'].astype(\"int64\")\n",
        "df_updated['xmax'] = df_updated['xmax'].astype(\"int64\")\n",
        "df_updated['ymin'] = df_updated['ymin'].astype(\"int64\")\n",
        "df_updated['ymax'] = df_updated['ymax'].astype(\"int64\")\n",
        "df_updated.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJrkPuvQiMyW",
        "outputId": "06935f9e-39f8-4eb0-dbaa-c438898dd879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1460 entries, 0 to 1459\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   filename  1460 non-null   object\n",
            " 1   width     1460 non-null   int64 \n",
            " 2   height    1460 non-null   int64 \n",
            " 3   name      1460 non-null   object\n",
            " 4   xmin      1460 non-null   int64 \n",
            " 5   xmax      1460 non-null   int64 \n",
            " 6   ymin      1460 non-null   int64 \n",
            " 7   ymax      1460 non-null   int64 \n",
            "dtypes: int64(6), object(2)\n",
            "memory usage: 91.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bbox_center_x = (df_updated['xmin'] + df_updated['xmax']) / 2\n",
        "bbox_center_y = (df_updated['ymin'] + df_updated['ymax']) / 2\n",
        "w = df_updated['xmax'] - df_updated['xmin']\n",
        "h = (df_updated['ymax'] - df_updated['ymin'])\n",
        "df_updated['center_x'] = np.round( bbox_center_x / df_updated['width'], 3)\n",
        "df_updated['center_y'] = np.round( bbox_center_y / df_updated['height'], 3)\n",
        "df_updated['width_norm'] = np.round( w / df_updated['width'], 3)\n",
        "df_updated['height_norm'] = np.round( h / df_updated['height'], 3)"
      ],
      "metadata": {
        "id": "hJEF8UTUiVF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#required labelling for YOLO -- Normalization of data as well\n",
        "df_updated.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "73z_oshTij_n",
        "outputId": "1e910258-b569-42a7-bf11-5ee7938e7eb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  filename  width  height   name  xmin  xmax  ymin  ymax  center_x  center_y  \\\n",
              "0    1.jpg    619     529  polyp   243   427    19   142     0.541     0.152   \n",
              "1    1.jpg    619     529  polyp   187   256   224   347     0.358     0.540   \n",
              "2    1.jpg    619     529  polyp   345   412   159   267     0.611     0.403   \n",
              "3    1.jpg    619     529  polyp   229   321   303   416     0.444     0.680   \n",
              "4    1.jpg    619     529  polyp   340   382   407   459     0.583     0.819   \n",
              "\n",
              "   width_norm  height_norm  \n",
              "0       0.297        0.233  \n",
              "1       0.111        0.233  \n",
              "2       0.108        0.204  \n",
              "3       0.149        0.214  \n",
              "4       0.068        0.098  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebb12c05-b2ab-459a-8d24-5396f5796cba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>name</th>\n",
              "      <th>xmin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymin</th>\n",
              "      <th>ymax</th>\n",
              "      <th>center_x</th>\n",
              "      <th>center_y</th>\n",
              "      <th>width_norm</th>\n",
              "      <th>height_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>243</td>\n",
              "      <td>427</td>\n",
              "      <td>19</td>\n",
              "      <td>142</td>\n",
              "      <td>0.541</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>187</td>\n",
              "      <td>256</td>\n",
              "      <td>224</td>\n",
              "      <td>347</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>345</td>\n",
              "      <td>412</td>\n",
              "      <td>159</td>\n",
              "      <td>267</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>229</td>\n",
              "      <td>321</td>\n",
              "      <td>303</td>\n",
              "      <td>416</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.149</td>\n",
              "      <td>0.214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>340</td>\n",
              "      <td>382</td>\n",
              "      <td>407</td>\n",
              "      <td>459</td>\n",
              "      <td>0.583</td>\n",
              "      <td>0.819</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb12c05-b2ab-459a-8d24-5396f5796cba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ebb12c05-b2ab-459a-8d24-5396f5796cba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ebb12c05-b2ab-459a-8d24-5396f5796cba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_updated[df_updated['center_y'] < 0].sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY3vor-BCeN5",
        "outputId": "41d7338a-35a4-4c39-a62b-13c18bf770f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "filename       0.0\n",
              "width          0.0\n",
              "height         0.0\n",
              "name           0.0\n",
              "xmin           0.0\n",
              "xmax           0.0\n",
              "ymin           0.0\n",
              "ymax           0.0\n",
              "center_x       0.0\n",
              "center_y       0.0\n",
              "width_norm     0.0\n",
              "height_norm    0.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = df['filename'].unique()\n",
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4XwlvwnilmC",
        "outputId": "fd1677e6-f6bf-4568-8bf6-4320682d4c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "997"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting in to 80%:20% percent ratios with random shuffle\n",
        "img_df = pd.DataFrame(images, columns=['filename'])\n",
        "img_train = tuple(img_df.sample(frac=0.8)['filename'])\n",
        "img_test = tuple(img_df.query(f'filename not in {img_train}')['filename'])"
      ],
      "metadata": {
        "id": "g9REMuYIippO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df_updated.query(f\"filename in {img_train}\")\n",
        "test_df = df_updated.query(f\"filename in {img_test}\")"
      ],
      "metadata": {
        "id": "Ery1b7Dti3YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df), len(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOPbdjxji5rU",
        "outputId": "b8d28a4c-269f-4de4-d765-58f7413670f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1175, 285)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df[train_df['name'] == 'polyp'].assign(id=0) \n",
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "V455fcw4jECB",
        "outputId": "6b967d3d-9981-48b7-d860-910bfa555337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     filename  width  height   name  xmin  xmax  ymin  ymax  center_x  \\\n",
              "0       1.jpg    619     529  polyp   243   427    19   142     0.541   \n",
              "1       1.jpg    619     529  polyp   187   256   224   347     0.358   \n",
              "2       1.jpg    619     529  polyp   345   412   159   267     0.611   \n",
              "3       1.jpg    619     529  polyp   229   321   303   416     0.444   \n",
              "4       1.jpg    619     529  polyp   340   382   407   459     0.583   \n",
              "...       ...    ...     ...    ...   ...   ...   ...   ...       ...   \n",
              "1453  994.jpg    621     531  polyp   488   607   268   399     0.882   \n",
              "1454  995.jpg    720     576  polyp   321   401   295   363     0.501   \n",
              "1457  997.jpg    600     528  polyp   287   391   304   427     0.565   \n",
              "1458  998.jpg    720     576  polyp   347   483   208   328     0.576   \n",
              "1459  999.jpg    622     529  polyp    97   346    45   336     0.356   \n",
              "\n",
              "      center_y  width_norm  height_norm  id  \n",
              "0        0.152       0.297        0.233   0  \n",
              "1        0.540       0.111        0.233   0  \n",
              "2        0.403       0.108        0.204   0  \n",
              "3        0.680       0.149        0.214   0  \n",
              "4        0.819       0.068        0.098   0  \n",
              "...        ...         ...          ...  ..  \n",
              "1453     0.628       0.192        0.247   0  \n",
              "1454     0.571       0.111        0.118   0  \n",
              "1457     0.692       0.173        0.233   0  \n",
              "1458     0.465       0.189        0.208   0  \n",
              "1459     0.360       0.400        0.550   0  \n",
              "\n",
              "[1175 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32729259-fb44-4284-be86-b94a3878889c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>name</th>\n",
              "      <th>xmin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymin</th>\n",
              "      <th>ymax</th>\n",
              "      <th>center_x</th>\n",
              "      <th>center_y</th>\n",
              "      <th>width_norm</th>\n",
              "      <th>height_norm</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>243</td>\n",
              "      <td>427</td>\n",
              "      <td>19</td>\n",
              "      <td>142</td>\n",
              "      <td>0.541</td>\n",
              "      <td>0.152</td>\n",
              "      <td>0.297</td>\n",
              "      <td>0.233</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>187</td>\n",
              "      <td>256</td>\n",
              "      <td>224</td>\n",
              "      <td>347</td>\n",
              "      <td>0.358</td>\n",
              "      <td>0.540</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.233</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>345</td>\n",
              "      <td>412</td>\n",
              "      <td>159</td>\n",
              "      <td>267</td>\n",
              "      <td>0.611</td>\n",
              "      <td>0.403</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.204</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>229</td>\n",
              "      <td>321</td>\n",
              "      <td>303</td>\n",
              "      <td>416</td>\n",
              "      <td>0.444</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.149</td>\n",
              "      <td>0.214</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.jpg</td>\n",
              "      <td>619</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>340</td>\n",
              "      <td>382</td>\n",
              "      <td>407</td>\n",
              "      <td>459</td>\n",
              "      <td>0.583</td>\n",
              "      <td>0.819</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.098</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1453</th>\n",
              "      <td>994.jpg</td>\n",
              "      <td>621</td>\n",
              "      <td>531</td>\n",
              "      <td>polyp</td>\n",
              "      <td>488</td>\n",
              "      <td>607</td>\n",
              "      <td>268</td>\n",
              "      <td>399</td>\n",
              "      <td>0.882</td>\n",
              "      <td>0.628</td>\n",
              "      <td>0.192</td>\n",
              "      <td>0.247</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1454</th>\n",
              "      <td>995.jpg</td>\n",
              "      <td>720</td>\n",
              "      <td>576</td>\n",
              "      <td>polyp</td>\n",
              "      <td>321</td>\n",
              "      <td>401</td>\n",
              "      <td>295</td>\n",
              "      <td>363</td>\n",
              "      <td>0.501</td>\n",
              "      <td>0.571</td>\n",
              "      <td>0.111</td>\n",
              "      <td>0.118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1457</th>\n",
              "      <td>997.jpg</td>\n",
              "      <td>600</td>\n",
              "      <td>528</td>\n",
              "      <td>polyp</td>\n",
              "      <td>287</td>\n",
              "      <td>391</td>\n",
              "      <td>304</td>\n",
              "      <td>427</td>\n",
              "      <td>0.565</td>\n",
              "      <td>0.692</td>\n",
              "      <td>0.173</td>\n",
              "      <td>0.233</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1458</th>\n",
              "      <td>998.jpg</td>\n",
              "      <td>720</td>\n",
              "      <td>576</td>\n",
              "      <td>polyp</td>\n",
              "      <td>347</td>\n",
              "      <td>483</td>\n",
              "      <td>208</td>\n",
              "      <td>328</td>\n",
              "      <td>0.576</td>\n",
              "      <td>0.465</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>999.jpg</td>\n",
              "      <td>622</td>\n",
              "      <td>529</td>\n",
              "      <td>polyp</td>\n",
              "      <td>97</td>\n",
              "      <td>346</td>\n",
              "      <td>45</td>\n",
              "      <td>336</td>\n",
              "      <td>0.356</td>\n",
              "      <td>0.360</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.550</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1175 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32729259-fb44-4284-be86-b94a3878889c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32729259-fb44-4284-be86-b94a3878889c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32729259-fb44-4284-be86-b94a3878889c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df[test_df['name'] == 'polyp'].assign(id=0)\n",
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "kDIsnXmKjxvH",
        "outputId": "29757130-5747-4475-e3f6-1a89799d69b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     filename  width  height   name  xmin  xmax  ymin  ymax  center_x  \\\n",
              "38     12.jpg    626     547  polyp   185   336    94   213     0.416   \n",
              "46    123.jpg    490     531  polyp   284   452   134   298     0.751   \n",
              "47    124.jpg    571     531  polyp   200   403   212   384     0.528   \n",
              "48    124.jpg    571     531  polyp   245   399   362   445     0.564   \n",
              "55     13.jpg    622     531  polyp   150   290   107   235     0.354   \n",
              "...       ...    ...     ...    ...   ...   ...   ...   ...       ...   \n",
              "1418   98.jpg    622     530  polyp   462   617   166   423     0.867   \n",
              "1426  981.jpg    720     576  polyp   218   434    96   347     0.453   \n",
              "1449  991.jpg    621     520  polyp   275   557   144   349     0.670   \n",
              "1455  996.jpg    585     530  polyp   294   423     4   199     0.613   \n",
              "1456  996.jpg    585     530  polyp   430   500   380   469     0.795   \n",
              "\n",
              "      center_y  width_norm  height_norm  id  \n",
              "38       0.281       0.241        0.218   0  \n",
              "46       0.407       0.343        0.309   0  \n",
              "47       0.561       0.356        0.324   0  \n",
              "48       0.760       0.270        0.156   0  \n",
              "55       0.322       0.225        0.241   0  \n",
              "...        ...         ...          ...  ..  \n",
              "1418     0.556       0.249        0.485   0  \n",
              "1426     0.385       0.300        0.436   0  \n",
              "1449     0.474       0.454        0.394   0  \n",
              "1455     0.192       0.221        0.368   0  \n",
              "1456     0.801       0.120        0.168   0  \n",
              "\n",
              "[285 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8d316ee-e1e0-4449-a5c3-f74050adf38f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>width</th>\n",
              "      <th>height</th>\n",
              "      <th>name</th>\n",
              "      <th>xmin</th>\n",
              "      <th>xmax</th>\n",
              "      <th>ymin</th>\n",
              "      <th>ymax</th>\n",
              "      <th>center_x</th>\n",
              "      <th>center_y</th>\n",
              "      <th>width_norm</th>\n",
              "      <th>height_norm</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>12.jpg</td>\n",
              "      <td>626</td>\n",
              "      <td>547</td>\n",
              "      <td>polyp</td>\n",
              "      <td>185</td>\n",
              "      <td>336</td>\n",
              "      <td>94</td>\n",
              "      <td>213</td>\n",
              "      <td>0.416</td>\n",
              "      <td>0.281</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0.218</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>123.jpg</td>\n",
              "      <td>490</td>\n",
              "      <td>531</td>\n",
              "      <td>polyp</td>\n",
              "      <td>284</td>\n",
              "      <td>452</td>\n",
              "      <td>134</td>\n",
              "      <td>298</td>\n",
              "      <td>0.751</td>\n",
              "      <td>0.407</td>\n",
              "      <td>0.343</td>\n",
              "      <td>0.309</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>124.jpg</td>\n",
              "      <td>571</td>\n",
              "      <td>531</td>\n",
              "      <td>polyp</td>\n",
              "      <td>200</td>\n",
              "      <td>403</td>\n",
              "      <td>212</td>\n",
              "      <td>384</td>\n",
              "      <td>0.528</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.356</td>\n",
              "      <td>0.324</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>124.jpg</td>\n",
              "      <td>571</td>\n",
              "      <td>531</td>\n",
              "      <td>polyp</td>\n",
              "      <td>245</td>\n",
              "      <td>399</td>\n",
              "      <td>362</td>\n",
              "      <td>445</td>\n",
              "      <td>0.564</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.156</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>13.jpg</td>\n",
              "      <td>622</td>\n",
              "      <td>531</td>\n",
              "      <td>polyp</td>\n",
              "      <td>150</td>\n",
              "      <td>290</td>\n",
              "      <td>107</td>\n",
              "      <td>235</td>\n",
              "      <td>0.354</td>\n",
              "      <td>0.322</td>\n",
              "      <td>0.225</td>\n",
              "      <td>0.241</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1418</th>\n",
              "      <td>98.jpg</td>\n",
              "      <td>622</td>\n",
              "      <td>530</td>\n",
              "      <td>polyp</td>\n",
              "      <td>462</td>\n",
              "      <td>617</td>\n",
              "      <td>166</td>\n",
              "      <td>423</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0.556</td>\n",
              "      <td>0.249</td>\n",
              "      <td>0.485</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1426</th>\n",
              "      <td>981.jpg</td>\n",
              "      <td>720</td>\n",
              "      <td>576</td>\n",
              "      <td>polyp</td>\n",
              "      <td>218</td>\n",
              "      <td>434</td>\n",
              "      <td>96</td>\n",
              "      <td>347</td>\n",
              "      <td>0.453</td>\n",
              "      <td>0.385</td>\n",
              "      <td>0.300</td>\n",
              "      <td>0.436</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1449</th>\n",
              "      <td>991.jpg</td>\n",
              "      <td>621</td>\n",
              "      <td>520</td>\n",
              "      <td>polyp</td>\n",
              "      <td>275</td>\n",
              "      <td>557</td>\n",
              "      <td>144</td>\n",
              "      <td>349</td>\n",
              "      <td>0.670</td>\n",
              "      <td>0.474</td>\n",
              "      <td>0.454</td>\n",
              "      <td>0.394</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1455</th>\n",
              "      <td>996.jpg</td>\n",
              "      <td>585</td>\n",
              "      <td>530</td>\n",
              "      <td>polyp</td>\n",
              "      <td>294</td>\n",
              "      <td>423</td>\n",
              "      <td>4</td>\n",
              "      <td>199</td>\n",
              "      <td>0.613</td>\n",
              "      <td>0.192</td>\n",
              "      <td>0.221</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>996.jpg</td>\n",
              "      <td>585</td>\n",
              "      <td>530</td>\n",
              "      <td>polyp</td>\n",
              "      <td>430</td>\n",
              "      <td>500</td>\n",
              "      <td>380</td>\n",
              "      <td>469</td>\n",
              "      <td>0.795</td>\n",
              "      <td>0.801</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.168</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>285 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8d316ee-e1e0-4449-a5c3-f74050adf38f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8d316ee-e1e0-4449-a5c3-f74050adf38f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8d316ee-e1e0-4449-a5c3-f74050adf38f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = '/content/drive/MyDrive/Polyp Detection/dataset/train'\n",
        "test_folder = '/content/drive/MyDrive/Polyp Detection/dataset/test'\n",
        "\n",
        "os.mkdir(train_folder)\n",
        "os.mkdir(test_folder)"
      ],
      "metadata": {
        "id": "tNybNlWLj_Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['filename', 'id', 'center_x',\t'center_y',\t'width_norm',\t'height_norm']\n",
        "groupby_obj_train = train_df[cols].groupby('filename')\n",
        "groupby_obj_test = test_df[cols].groupby('filename')"
      ],
      "metadata": {
        "id": "UmhRzHSBjBJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data(filename, folder_path, group_obj):\n",
        "  src = os.path.join('/content/drive/MyDrive/Polyp Detection/dataset', filename)\n",
        "  dst = os.path.join(folder_path, filename)\n",
        "  move(src, dst)\n",
        "\n",
        "  text_filename = os.path.join(folder_path, os.path.splitext(filename)[0] + '.txt')\n",
        "  group_obj.get_group(filename).set_index('filename').to_csv(text_filename, sep=' ', index=False, header=False)"
      ],
      "metadata": {
        "id": "luZN54Vzi70r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename_series = pd.Series(groupby_obj_train.groups.keys())\n",
        "filename_series.apply(save_data, args=(train_folder, groupby_obj_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWRXehBhpwNU",
        "outputId": "3088136e-35f5-4174-d080-caf7bc6f445f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "793    None\n",
              "794    None\n",
              "795    None\n",
              "796    None\n",
              "797    None\n",
              "Length: 798, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename_series_test = pd.Series(groupby_obj_test.groups.keys())\n",
        "filename_series_test.apply(save_data, args=(test_folder, groupby_obj_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hepxgSThpzRx",
        "outputId": "c530c86c-8328-4ccc-9333-0e2730e2ce4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      None\n",
              "1      None\n",
              "2      None\n",
              "3      None\n",
              "4      None\n",
              "       ... \n",
              "194    None\n",
              "195    None\n",
              "196    None\n",
              "197    None\n",
              "198    None\n",
              "Length: 199, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in os.listdir('/content/drive/MyDrive/Polyp Detection/dataset'):\n",
        "  if os.path.splitext(i)[1] == '.xml':\n",
        "    path = '/content/drive/MyDrive/Polyp Detection/dataset/' + i\n",
        "    os.remove(path)"
      ],
      "metadata": {
        "id": "dQSy2Tf-qUFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jv9Vp6YJqcHl",
        "outputId": "52a0f471-6090-4264-bf49-efd54dbafb86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Polyp Detection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Polyp Detection/yolov5') "
      ],
      "metadata": {
        "id": "z_SDQ38UuUSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97uOvf7GujDJ",
        "outputId": "cbcebe92-6eb3-44a0-fc6f-14cd3c2e2b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benchmarks.py\t detect.py   __pycache__       segment\t       val.py\n",
            "CITATION.cff\t export.py   README.md\t       setup.cfg       yolov5l6.pt\n",
            "classify\t hubconf.py  README.zh-CN.md   train.py        yolov5x.pt\n",
            "CONTRIBUTING.md  LICENSE     requirements.txt  tutorial.ipynb\n",
            "data\t\t models      runs\t       utils\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHQoZRIjulbv",
        "outputId": "ece38201-5a00-443f-a35d-711ad127d179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gitpython\n",
            "  Downloading GitPython-3.1.29-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 6)) (7.9.0)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 7)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 8)) (1.21.6)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 9)) (4.6.0.66)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 10)) (7.1.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 11)) (5.4.8)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 12)) (6.0)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 14)) (1.7.3)\n",
            "Collecting thop>=0.1.1\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 16)) (1.13.0+cu116)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 17)) (0.14.0+cu116)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 18)) (4.64.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 22)) (2.9.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 27)) (1.3.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 28)) (0.11.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.23.0->-r requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.7.0->-r requirements.txt (line 16)) (4.4.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.4.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.51.1)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.4.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.38.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.6)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.2.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 22)) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 22)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 22)) (3.2.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (5.7.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->-r requirements.txt (line 6)) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->-r requirements.txt (line 6)) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->-r requirements.txt (line 6)) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->-r requirements.txt (line 6)) (0.7.0)\n",
            "Installing collected packages: smmap, jedi, gitdb, thop, gitpython\n",
            "Successfully installed gitdb-4.0.10 gitpython-3.1.29 jedi-0.18.2 smmap-5.0.0 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5x.pt --batch 8 --name Model --img 640 --epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GkZ9Fzrw6Us",
        "outputId": "1e65ffbc-5235-46ea-ab83-6a893263a956"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 116MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n",
            "100% 166M/166M [00:01<00:00, 128MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:03<00:00, 225.86it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Polyp Detection/dataset/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:01<00:00, 113.70it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Polyp Detection/dataset/test.cache\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      7.47G    0.08241    0.03355          0         13        640: 100% 100/100 [01:06<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  1.91it/s]\n",
            "                   all        199        285      0.379      0.509      0.359      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      9.85G    0.05654    0.02817          0         22        640: 100% 100/100 [01:05<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.43it/s]\n",
            "                   all        199        285      0.413      0.547      0.408      0.175\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      9.85G    0.05014    0.02549          0         21        640: 100% 100/100 [01:06<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.48it/s]\n",
            "                   all        199        285       0.68      0.667      0.673      0.299\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      9.85G    0.04254    0.02309          0         13        640: 100% 100/100 [01:05<00:00,  1.53it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.49it/s]\n",
            "                   all        199        285      0.805      0.696      0.788      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      9.85G     0.0398     0.0226          0         17        640: 100% 100/100 [01:06<00:00,  1.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.51it/s]\n",
            "                   all        199        285      0.846      0.672      0.788      0.445\n",
            "\n",
            "5 epochs completed in 0.108 hours.\n",
            "Optimizer stripped from runs/train/Model/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/Model/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/Model/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  2.17it/s]\n",
            "                   all        199        285      0.846      0.672      0.788      0.446\n",
            "Results saved to \u001b[1mruns/train/Model\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5x.pt --batch 8 --name Model --img 640 --epochs 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUQDx0b7XIox",
        "outputId": "dfcc4602-0867-458c-8b9b-6492448981df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 54.2MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model2/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model2\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/14      7.47G    0.08241    0.03355          0         13        640: 100% 100/100 [05:39<00:00,  3.40s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  1.92it/s]\n",
            "                   all        199        285      0.379      0.509      0.359      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/14      9.85G    0.05716    0.02782          0         22        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.53it/s]\n",
            "                   all        199        285      0.607      0.611      0.609      0.294\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/14      9.85G    0.05253    0.02502          0         21        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.64it/s]\n",
            "                   all        199        285      0.555      0.568      0.517      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/14      9.85G    0.04601    0.02257          0         13        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.522      0.593      0.521      0.226\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/14      9.85G    0.04241    0.02228          0         17        640: 100% 100/100 [01:00<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.41it/s]\n",
            "                   all        199        285      0.814      0.681      0.791      0.479\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/14      9.85G    0.03871    0.02083          0         17        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.689      0.692      0.752      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/14      9.85G     0.0368    0.02008          0         11        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.828      0.716      0.815      0.481\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/14      9.85G    0.03535    0.02062          0         14        640: 100% 100/100 [01:01<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.64it/s]\n",
            "                   all        199        285      0.883      0.634      0.778      0.474\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/14      9.85G    0.03374    0.02012          0         18        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.845      0.669      0.789      0.497\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/14      9.85G    0.03193    0.01811          0         12        640: 100% 100/100 [01:00<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.27it/s]\n",
            "                   all        199        285      0.846      0.673      0.808      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/14      9.85G    0.03068    0.01821          0         18        640: 100% 100/100 [01:00<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.759      0.772      0.833      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/14      9.85G    0.02884    0.01751          0         11        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.36it/s]\n",
            "                   all        199        285      0.868      0.692      0.825      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/14      9.85G    0.02756    0.01788          0         21        640: 100% 100/100 [01:01<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.863      0.729      0.832       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/14      9.85G    0.02601    0.01668          0         22        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.805      0.726      0.812      0.533\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/14      9.85G    0.02582    0.01616          0         18        640: 100% 100/100 [01:00<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.64it/s]\n",
            "                   all        199        285      0.827      0.747      0.825       0.55\n",
            "\n",
            "15 epochs completed in 0.372 hours.\n",
            "Optimizer stripped from runs/train/Model2/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/Model2/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/Model2/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  2.04it/s]\n",
            "                   all        199        285      0.863       0.73      0.832       0.55\n",
            "Results saved to \u001b[1mruns/train/Model2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5x.pt --batch 8 --name Model --img 640 --epochs 25"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud4GMm0TXN0D",
        "outputId": "fd71b69c-4b40-4706-fb9a-63ccf72d4391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=25, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model3/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model3\u001b[0m\n",
            "Starting training for 25 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/24      7.47G    0.08241    0.03355          0         13        640: 100% 100/100 [01:06<00:00,  1.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.23it/s]\n",
            "                   all        199        285      0.379      0.509      0.359      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/24      9.85G     0.0572    0.02779          0         22        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.52it/s]\n",
            "                   all        199        285      0.563      0.584      0.571      0.263\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/24      9.85G    0.05273    0.02511          0         21        640: 100% 100/100 [01:01<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.60it/s]\n",
            "                   all        199        285      0.604      0.677       0.66      0.295\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/24      9.85G    0.04564     0.0228          0         13        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.61it/s]\n",
            "                   all        199        285      0.516      0.614      0.545      0.286\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/24      9.85G     0.0435    0.02238          0         17        640: 100% 100/100 [01:00<00:00,  1.66it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.55it/s]\n",
            "                   all        199        285      0.832      0.712      0.811       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/24      9.85G    0.03935    0.02101          0         17        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.60it/s]\n",
            "                   all        199        285      0.799      0.663      0.748      0.446\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/24      9.85G    0.03776     0.0204          0         11        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.61it/s]\n",
            "                   all        199        285      0.779      0.719      0.808       0.47\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/24      9.85G    0.03655    0.02092          0         14        640: 100% 100/100 [01:01<00:00,  1.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.742      0.715      0.785      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/24      9.85G    0.03528    0.02046          0         18        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.818      0.719      0.819      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/24      9.85G    0.03366    0.01834          0         12        640: 100% 100/100 [01:01<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.52it/s]\n",
            "                   all        199        285      0.809      0.688      0.789      0.482\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/24      9.85G    0.03263    0.01888          0         18        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.742      0.799      0.827      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/24      9.85G    0.03105    0.01806          0         11        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.61it/s]\n",
            "                   all        199        285      0.833      0.789      0.833      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/24      9.85G    0.03036    0.01869          0         21        640: 100% 100/100 [01:02<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.61it/s]\n",
            "                   all        199        285      0.867      0.754      0.834      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/24      9.85G    0.02911    0.01738          0         22        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.60it/s]\n",
            "                   all        199        285      0.851      0.699      0.803      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/24      9.85G    0.02846    0.01681          0         18        640: 100% 100/100 [01:00<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.787      0.714      0.795      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/24      9.85G    0.02748    0.01642          0         19        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.747      0.761      0.813      0.504\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/24      9.85G    0.02663     0.0166          0         19        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.856      0.712       0.83      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/24      9.85G    0.02547    0.01591          0         18        640: 100% 100/100 [01:01<00:00,  1.64it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.827      0.723      0.818      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/24      9.85G     0.0256     0.0154          0         21        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.785      0.728      0.802      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/24      9.85G    0.02514    0.01547          0         14        640: 100% 100/100 [01:00<00:00,  1.65it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.826      0.735      0.812      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/24      9.85G    0.02441    0.01515          0         16        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.896      0.737      0.836      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/24      9.85G    0.02355    0.01429          0         12        640: 100% 100/100 [01:00<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.876      0.746      0.826      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/24      9.85G    0.02231    0.01398          0         13        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.887      0.723      0.821      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/24      9.85G    0.02195    0.01351          0         10        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.862      0.765       0.83       0.55\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/24      9.85G    0.02135    0.01385          0         12        640: 100% 100/100 [01:01<00:00,  1.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.64it/s]\n",
            "                   all        199        285      0.873      0.768      0.841      0.558\n",
            "\n",
            "25 epochs completed in 0.485 hours.\n",
            "Optimizer stripped from runs/train/Model3/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/Model3/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/Model3/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  2.14it/s]\n",
            "                   all        199        285      0.872      0.768      0.841      0.558\n",
            "Results saved to \u001b[1mruns/train/Model3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5x.pt --batch 8 --name Model --img 640 --epochs 35"
      ],
      "metadata": {
        "id": "IBWq2_njsCSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e0b625-f405-47fe-f509-797250a5657e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=35, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 112MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model4/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model4\u001b[0m\n",
            "Starting training for 35 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/34      7.47G    0.08241    0.03355          0         13        640: 100% 100/100 [08:10<00:00,  4.91s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  1.99it/s]\n",
            "                   all        199        285      0.379      0.509      0.359      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/34      9.85G    0.05739    0.02778          0         22        640: 100% 100/100 [00:57<00:00,  1.74it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.411      0.526      0.404      0.194\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/34      9.85G    0.05255    0.02505          0         21        640: 100% 100/100 [00:57<00:00,  1.75it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.72it/s]\n",
            "                   all        199        285      0.612      0.547      0.601      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/34      9.85G     0.0465    0.02248          0         13        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.70it/s]\n",
            "                   all        199        285      0.586      0.577      0.554      0.241\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/34      9.85G    0.04344    0.02218          0         17        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.857      0.654      0.774      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/34      9.85G    0.03876    0.02088          0         17        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.779      0.646      0.754      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/34      9.85G    0.03772    0.02029          0         11        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.809      0.653       0.75      0.445\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/34      9.85G    0.03689    0.02091          0         14        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.787      0.685      0.784      0.476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/34      9.85G    0.03486    0.02077          0         18        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.793      0.649      0.734      0.423\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/34      9.85G    0.03511    0.01886          0         12        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.839      0.693      0.798      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/34      9.85G    0.03322    0.01921          0         18        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285        0.8      0.702      0.794       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/34      9.85G     0.0323    0.01853          0         11        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.793      0.681      0.788      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/34      9.85G    0.03184    0.01908          0         21        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.814      0.688      0.796      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/34      9.85G    0.03019    0.01778          0         22        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.788      0.731      0.822       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/34      9.85G    0.02986    0.01752          0         18        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.785      0.751      0.814      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/34      9.85G    0.02883    0.01701          0         19        640: 100% 100/100 [01:00<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.64it/s]\n",
            "                   all        199        285      0.777      0.751      0.805      0.514\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/34      9.85G    0.02803    0.01718          0         19        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.825      0.726      0.818      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/34      9.85G    0.02701    0.01707          0         18        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.771      0.754      0.812      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/34      9.85G     0.0273    0.01613          0         21        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.798      0.749      0.815       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/34      9.85G    0.02705    0.01611          0         14        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.801      0.747      0.818      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/34      9.85G    0.02613    0.01589          0         16        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.843      0.733      0.807      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/34      9.85G    0.02546    0.01492          0         12        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.817      0.753      0.808      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/34      9.85G     0.0249    0.01492          0         13        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.34it/s]\n",
            "                   all        199        285      0.843      0.733      0.788      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/34      9.85G    0.02367    0.01434          0         10        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.809      0.702      0.771      0.494\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/34      9.85G    0.02296    0.01477          0         12        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.64it/s]\n",
            "                   all        199        285      0.842      0.712      0.793      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/34      9.85G    0.02313    0.01421          0         16        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.823      0.747        0.8      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/34      9.85G    0.02193    0.01441          0         12        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.54it/s]\n",
            "                   all        199        285       0.86      0.712      0.798      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/34      9.85G    0.02149    0.01342          0         12        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.844      0.737       0.81      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/34      9.85G      0.021    0.01296          0          9        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.799      0.754      0.802      0.531\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/34      9.85G    0.02068    0.01283          0         13        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.881      0.691      0.795      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/34      9.85G    0.02025    0.01216          0         20        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.895      0.702      0.799      0.536\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/34      9.85G    0.01975    0.01312          0         13        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.842      0.765      0.804      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/34      9.85G    0.01953    0.01209          0         18        640: 100% 100/100 [00:58<00:00,  1.72it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.69it/s]\n",
            "                   all        199        285      0.849      0.723      0.795      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/34      9.85G    0.01922    0.01195          0         15        640: 100% 100/100 [00:57<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.837      0.751      0.785      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/34      9.85G    0.01821    0.01188          0         19        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.843      0.737      0.784      0.516\n",
            "\n",
            "35 epochs completed in 0.775 hours.\n",
            "Optimizer stripped from runs/train/Model4/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/Model4/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/Model4/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  2.06it/s]\n",
            "                   all        199        285      0.798      0.749      0.814      0.539\n",
            "Results saved to \u001b[1mruns/train/Model4\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5x.pt --batch 8 --name Model --img 640 --epochs 30"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjXudi-_rbRg",
        "outputId": "a31d4bee-c80d-4206-e080-a2c0cea2703d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "Command 'git fetch origin' timed out after 5 seconds\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 21 (delta 8), reused 10 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "From https://github.com/ultralytics/yolov5\n",
            "   3c1afd9..65071da  master     -> origin/master\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 163MB/s]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model5/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model5\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      7.47G    0.08241    0.03355          0         13        640: 100% 100/100 [07:55<00:00,  4.76s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  1.95it/s]\n",
            "                   all        199        285      0.379      0.509      0.359      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29      9.85G    0.05703    0.02783          0         22        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.61it/s]\n",
            "                   all        199        285      0.539      0.558      0.511      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29      9.85G    0.05367    0.02496          0         21        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.723      0.568      0.635      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29      9.85G    0.04664    0.02258          0         13        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.751      0.681      0.764       0.36\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29      9.85G    0.04363    0.02237          0         17        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.805      0.723       0.81      0.496\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29      9.85G     0.0394     0.0209          0         17        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.69it/s]\n",
            "                   all        199        285      0.841      0.653      0.794      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29      9.85G    0.03763    0.02025          0         11        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.748      0.772      0.821      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29      9.85G    0.03611    0.02063          0         14        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.69it/s]\n",
            "                   all        199        285      0.893      0.642      0.789       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29      9.85G    0.03522    0.02063          0         18        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.832       0.73      0.804      0.493\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29      9.85G    0.03438    0.01856          0         12        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.786      0.716      0.787      0.498\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29      9.85G    0.03352    0.01894          0         18        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.757      0.754      0.801      0.488\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29      9.85G    0.03188    0.01841          0         11        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285       0.82      0.702       0.81      0.525\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29      9.85G    0.03108    0.01886          0         21        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.69it/s]\n",
            "                   all        199        285      0.782      0.726      0.811      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29      9.85G    0.02973    0.01772          0         22        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.59it/s]\n",
            "                   all        199        285      0.852      0.688      0.795      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29      9.85G    0.02906    0.01704          0         18        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.816      0.737      0.798      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29      9.85G    0.02865    0.01687          0         19        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.778       0.74      0.813      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29      9.85G    0.02793    0.01702          0         19        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.853      0.711      0.824      0.543\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29      9.85G    0.02636    0.01648          0         18        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.833      0.733      0.816      0.535\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29      9.85G    0.02656    0.01556          0         21        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.763      0.691      0.754      0.491\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29      9.85G    0.02634    0.01608          0         14        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.797      0.775      0.815      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29      9.85G    0.02522    0.01562          0         16        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.832      0.733      0.807      0.512\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29      9.85G    0.02437    0.01486          0         12        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.832      0.746      0.818      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29      9.85G    0.02326    0.01468          0         13        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.854      0.744      0.818      0.534\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29      9.85G    0.02241     0.0139          0         10        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.816      0.733       0.81      0.523\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29      9.85G     0.0222    0.01429          0         12        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.901      0.706       0.82      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29      9.85G    0.02235     0.0136          0         16        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.847      0.738      0.806      0.529\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29      9.85G    0.02137    0.01398          0         12        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.881      0.753      0.812       0.54\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29      9.85G     0.0206      0.013          0         12        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.45it/s]\n",
            "                   all        199        285       0.84      0.744      0.811      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29      9.85G     0.0203    0.01258          0          9        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.866      0.758      0.816      0.537\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29      9.85G    0.01995     0.0126          0         13        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.69it/s]\n",
            "                   all        199        285      0.844      0.757      0.801      0.527\n",
            "\n",
            "30 epochs completed in 0.679 hours.\n",
            "Optimizer stripped from runs/train/Model5/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/Model5/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/Model5/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.18it/s]\n",
            "                   all        199        285      0.857      0.714      0.825      0.543\n",
            "Results saved to \u001b[1mruns/train/Model5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5x.pt --batch 8 --name Model --img 640 --epochs 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VL8kjorg2pp7",
        "outputId": "ecbe2137-30d1-4523-c4aa-bf65091f1ff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=32, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n",
            "  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n",
            "  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n",
            "  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n",
            "  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n",
            "  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n",
            "  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n",
            "  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n",
            "  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n",
            "  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n",
            " 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n",
            " 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n",
            " 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n",
            " 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n",
            " 24      [17, 20, 23]  1     40374  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n",
            "Model summary: 445 layers, 86217814 parameters, 86217814 gradients, 204.6 GFLOPs\n",
            "\n",
            "Transferred 739/745 items from yolov5x.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model7/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model7\u001b[0m\n",
            "Starting training for 32 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/31      7.47G    0.08241    0.03355          0         13        640: 100% 100/100 [01:04<00:00,  1.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.27it/s]\n",
            "                   all        199        285      0.379      0.509      0.359      0.119\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/31      9.85G    0.05731    0.02779          0         22        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.59it/s]\n",
            "                   all        199        285      0.401      0.561      0.409       0.18\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/31      9.85G    0.05346    0.02509          0         21        640: 100% 100/100 [00:59<00:00,  1.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.683      0.618      0.672      0.338\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/31      9.85G    0.04621    0.02268          0         13        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285       0.78      0.649      0.748      0.353\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/31      9.85G    0.04275    0.02245          0         17        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.63it/s]\n",
            "                   all        199        285      0.785      0.695      0.764      0.454\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/31      9.85G    0.03972     0.0212          0         17        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285      0.743      0.712      0.798      0.466\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/31      9.85G    0.03822    0.02052          0         11        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.834      0.621      0.775      0.473\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/31      9.85G    0.03684    0.02108          0         14        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.65it/s]\n",
            "                   all        199        285       0.84      0.635      0.772       0.46\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/31      9.85G    0.03566    0.02104          0         18        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.841      0.707      0.799      0.486\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/31      9.85G    0.03397     0.0187          0         12        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285       0.87      0.706      0.838        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/31      9.85G    0.03364      0.019          0         18        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.759       0.75      0.808      0.499\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/31      9.85G    0.03211    0.01832          0         11        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.749      0.772      0.812      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/31      9.85G    0.03169    0.01882          0         21        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.845      0.698      0.822      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/31      9.85G    0.02966    0.01741          0         22        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.748      0.691      0.773      0.475\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/31      9.85G    0.02925    0.01725          0         18        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.817      0.688      0.797      0.502\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/31      9.85G    0.02896    0.01676          0         19        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285       0.77      0.667      0.768      0.483\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/31      9.85G    0.02822    0.01729          0         19        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.785      0.782      0.828      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/31      9.85G    0.02672    0.01646          0         18        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.40it/s]\n",
            "                   all        199        285      0.808      0.723        0.8      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/31      9.85G    0.02664    0.01562          0         21        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.812      0.719      0.803      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/31      9.85G    0.02619    0.01585          0         14        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285       0.91      0.711      0.819      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/31      9.85G    0.02579    0.01566          0         16        640: 100% 100/100 [00:59<00:00,  1.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.862       0.74      0.822      0.515\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/31      9.85G    0.02537    0.01491          0         12        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.819      0.729      0.801      0.519\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/31      9.85G    0.02432    0.01492          0         13        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.834      0.739      0.819      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/31      9.85G    0.02313    0.01414          0         10        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.882      0.726       0.82      0.518\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/31      9.85G    0.02259    0.01425          0         12        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.862      0.748      0.815      0.538\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/31      9.85G    0.02252     0.0138          0         16        640: 100% 100/100 [00:59<00:00,  1.68it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.67it/s]\n",
            "                   all        199        285      0.796      0.772      0.799      0.513\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/31      9.85G    0.02163     0.0141          0         12        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.831      0.758      0.809      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/31      9.85G    0.02103    0.01328          0         12        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.822      0.779      0.816       0.52\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/31      9.85G    0.02061    0.01282          0          9        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.862      0.746       0.81      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/31      9.85G    0.01992    0.01252          0         13        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.68it/s]\n",
            "                   all        199        285      0.856      0.744      0.804      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/31      9.85G    0.01993    0.01193          0         20        640: 100% 100/100 [00:58<00:00,  1.70it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.62it/s]\n",
            "                   all        199        285      0.879       0.74      0.804      0.521\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/31      9.85G     0.0193    0.01288          0         13        640: 100% 100/100 [00:58<00:00,  1.71it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  2.66it/s]\n",
            "                   all        199        285      0.859      0.767      0.802      0.515\n",
            "\n",
            "32 epochs completed in 0.605 hours.\n",
            "Optimizer stripped from runs/train/Model7/weights/last.pt, 173.1MB\n",
            "Optimizer stripped from runs/train/Model7/weights/best.pt, 173.1MB\n",
            "\n",
            "Validating runs/train/Model7/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 322 layers, 86173414 parameters, 0 gradients, 203.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:06<00:00,  2.16it/s]\n",
            "                   all        199        285      0.862      0.748      0.815      0.538\n",
            "Results saved to \u001b[1mruns/train/Model7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5l6.pt --batch 4 --name Model --img 1280 --epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NARfLFYC_60N",
        "outputId": "3139e12a-355c-4b69-e636-29ab66fd42ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l6.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=4, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n",
            "  8                -1  3   5611008  models.common.C3                        [768, 768, 3]                 \n",
            "  9                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n",
            " 10                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            " 11                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 12                -1  1    787968  models.common.Conv                      [1024, 768, 1, 1]             \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  3   6200832  models.common.C3                        [1536, 768, 3, False]         \n",
            " 16                -1  1    394240  models.common.Conv                      [768, 512, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 20                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 27                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  3   5807616  models.common.C3                        [1024, 768, 3, False]         \n",
            " 30                -1  1   5309952  models.common.Conv                      [768, 768, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  3  10496000  models.common.C3                        [1536, 1024, 3, False]        \n",
            " 33  [23, 26, 29, 32]  1     46152  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024]]\n",
            "Model summary: 477 layers, 76162504 parameters, 76162504 gradients, 110.5 GFLOPs\n",
            "\n",
            "Transferred 787/795 items from yolov5l6.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 131 weight(decay=0.0), 135 weight(decay=0.0005), 135 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m7.10 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model9/labels.jpg... \n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model9\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4      10.3G    0.07208    0.04759          0          6       1280: 100% 200/200 [02:11<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:11<00:00,  2.20it/s]\n",
            "                   all        199        285      0.268      0.533      0.353      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      14.3G    0.04836    0.03176          0          7       1280: 100% 200/200 [02:05<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10<00:00,  2.43it/s]\n",
            "                   all        199        285      0.565      0.607       0.57       0.29\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      14.3G    0.04346    0.02659          0          4       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.55it/s]\n",
            "                   all        199        285      0.641      0.632      0.601      0.298\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      14.3G    0.03622    0.02405          0          5       1280: 100% 200/200 [02:05<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.56it/s]\n",
            "                   all        199        285      0.798      0.688       0.77      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      14.3G    0.03425    0.02309          0          8       1280: 100% 200/200 [02:05<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.57it/s]\n",
            "                   all        199        285      0.776      0.718      0.793      0.468\n",
            "\n",
            "5 epochs completed in 0.197 hours.\n",
            "Optimizer stripped from runs/train/Model9/weights/last.pt, 153.6MB\n",
            "Optimizer stripped from runs/train/Model9/weights/best.pt, 153.6MB\n",
            "\n",
            "Validating runs/train/Model9/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 346 layers, 76118664 parameters, 0 gradients, 109.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:11<00:00,  2.18it/s]\n",
            "                   all        199        285      0.776      0.719      0.793      0.468\n",
            "Results saved to \u001b[1mruns/train/Model9\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5l6.pt --batch 4 --name Model --img 1280 --epochs 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBol83slDIEy",
        "outputId": "ff0535a3-a50d-4bfb-b914-3c835ac4aac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l6.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=4, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n",
            "  8                -1  3   5611008  models.common.C3                        [768, 768, 3]                 \n",
            "  9                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n",
            " 10                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            " 11                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 12                -1  1    787968  models.common.Conv                      [1024, 768, 1, 1]             \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  3   6200832  models.common.C3                        [1536, 768, 3, False]         \n",
            " 16                -1  1    394240  models.common.Conv                      [768, 512, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 20                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 27                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  3   5807616  models.common.C3                        [1024, 768, 3, False]         \n",
            " 30                -1  1   5309952  models.common.Conv                      [768, 768, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  3  10496000  models.common.C3                        [1536, 1024, 3, False]        \n",
            " 33  [23, 26, 29, 32]  1     46152  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024]]\n",
            "Model summary: 477 layers, 76162504 parameters, 76162504 gradients, 110.5 GFLOPs\n",
            "\n",
            "Transferred 787/795 items from yolov5l6.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 131 weight(decay=0.0), 135 weight(decay=0.0005), 135 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m7.10 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model10/labels.jpg... \n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model10\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9      10.3G    0.07208    0.04759          0          6       1280: 100% 200/200 [02:11<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:11<00:00,  2.25it/s]\n",
            "                   all        199        285      0.268      0.533      0.353      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      14.3G    0.04926    0.03134          0          7       1280: 100% 200/200 [02:05<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.51it/s]\n",
            "                   all        199        285      0.548      0.607      0.569      0.282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      14.3G    0.04443    0.02602          0          4       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.56it/s]\n",
            "                   all        199        285      0.644      0.572      0.609       0.28\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      14.3G    0.03901     0.0236          0          5       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.655      0.649      0.677      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      14.3G     0.0362    0.02282          0          8       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10<00:00,  2.49it/s]\n",
            "                   all        199        285      0.815      0.604      0.722      0.365\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      14.3G    0.03239    0.02112          0          3       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.59it/s]\n",
            "                   all        199        285      0.752      0.691      0.749      0.439\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      14.3G    0.02978    0.02056          0          4       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.59it/s]\n",
            "                   all        199        285      0.788      0.737       0.79      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      14.3G    0.02811    0.02086          0          6       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.834      0.691      0.795      0.516\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      14.3G     0.0267     0.0208          0         10       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.59it/s]\n",
            "                   all        199        285      0.833      0.719       0.81      0.526\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      14.3G     0.0246    0.01845          0          2       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.833      0.726      0.808       0.54\n",
            "\n",
            "10 epochs completed in 0.391 hours.\n",
            "Optimizer stripped from runs/train/Model10/weights/last.pt, 153.6MB\n",
            "Optimizer stripped from runs/train/Model10/weights/best.pt, 153.6MB\n",
            "\n",
            "Validating runs/train/Model10/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 346 layers, 76118664 parameters, 0 gradients, 109.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10<00:00,  2.30it/s]\n",
            "                   all        199        285      0.833      0.726      0.808       0.54\n",
            "Results saved to \u001b[1mruns/train/Model10\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKbqHF7EIzst",
        "outputId": "1c97fbe5-201a-45e6-9f52-d465a2d79a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 27 19:51:26 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   72C    P0    28W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5l6.pt --batch 4 --name Model --img 1280 --epochs 15"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyk95E-8I1nj",
        "outputId": "244806a5-6f89-41ae-9325-4f28ac88ceb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5l6.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=15, batch_size=4, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
            "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
            "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
            "  7                -1  1   3540480  models.common.Conv                      [512, 768, 3, 2]              \n",
            "  8                -1  3   5611008  models.common.C3                        [768, 768, 3]                 \n",
            "  9                -1  1   7079936  models.common.Conv                      [768, 1024, 3, 2]             \n",
            " 10                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
            " 11                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               \n",
            " 12                -1  1    787968  models.common.Conv                      [1024, 768, 1, 1]             \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  3   6200832  models.common.C3                        [1536, 768, 3, False]         \n",
            " 16                -1  1    394240  models.common.Conv                      [768, 512, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         \n",
            " 20                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  3    690688  models.common.C3                        [512, 256, 3, False]          \n",
            " 24                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          \n",
            " 27                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  3   5807616  models.common.C3                        [1024, 768, 3, False]         \n",
            " 30                -1  1   5309952  models.common.Conv                      [768, 768, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  3  10496000  models.common.C3                        [1536, 1024, 3, False]        \n",
            " 33  [23, 26, 29, 32]  1     46152  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [256, 512, 768, 1024]]\n",
            "Model summary: 477 layers, 76162504 parameters, 76162504 gradients, 110.5 GFLOPs\n",
            "\n",
            "Transferred 787/795 items from yolov5l6.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 131 weight(decay=0.0), 135 weight(decay=0.0005), 135 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m7.10 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model11/labels.jpg... \n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model11\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/14      10.3G    0.07208    0.04759          0          6       1280: 100% 200/200 [02:11<00:00,  1.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:11<00:00,  2.21it/s]\n",
            "                   all        199        285      0.268      0.533      0.353      0.123\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/14      14.3G    0.04922    0.03132          0          7       1280: 100% 200/200 [02:05<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.50it/s]\n",
            "                   all        199        285      0.528      0.526      0.504      0.238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/14      14.3G    0.04487    0.02583          0          4       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.56it/s]\n",
            "                   all        199        285      0.486      0.635      0.563      0.247\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/14      14.3G     0.0399     0.0232          0          5       1280: 100% 200/200 [02:05<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.599      0.598      0.639      0.344\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/14      14.3G     0.0367    0.02261          0          8       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.793      0.671      0.751      0.408\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/14      14.3G    0.03319    0.02086          0          3       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.746      0.698      0.756      0.427\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/14      14.3G    0.03079    0.02045          0          4       1280: 100% 200/200 [02:05<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285       0.74      0.718       0.77      0.462\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/14      14.3G    0.03014    0.02114          0          6       1280: 100% 200/200 [02:05<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.851      0.679      0.797      0.501\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/14      14.3G    0.02812    0.02091          0         10       1280: 100% 200/200 [02:05<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.831      0.706      0.801        0.5\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/14      14.3G    0.02683    0.01891          0          2       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.831      0.674      0.795      0.505\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/14      14.3G    0.02595    0.01917          0          5       1280: 100% 200/200 [02:04<00:00,  1.61it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.57it/s]\n",
            "                   all        199        285      0.782      0.744      0.816      0.527\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/14      14.3G    0.02415    0.01846          0          3       1280: 100% 200/200 [02:05<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.59it/s]\n",
            "                   all        199        285      0.834      0.681      0.799      0.524\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/14      14.3G    0.02382    0.01887          0          8       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.58it/s]\n",
            "                   all        199        285      0.871      0.719      0.812      0.549\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/14      14.3G    0.02204    0.01774          0          4       1280: 100% 200/200 [02:05<00:00,  1.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.59it/s]\n",
            "                   all        199        285      0.811       0.74      0.816      0.539\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/14      14.3G    0.02158    0.01695          0          1       1280: 100% 200/200 [02:04<00:00,  1.60it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:09<00:00,  2.59it/s]\n",
            "                   all        199        285      0.841      0.685      0.811      0.545\n",
            "\n",
            "15 epochs completed in 0.584 hours.\n",
            "Optimizer stripped from runs/train/Model11/weights/last.pt, 153.6MB\n",
            "Optimizer stripped from runs/train/Model11/weights/best.pt, 153.6MB\n",
            "\n",
            "Validating runs/train/Model11/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 346 layers, 76118664 parameters, 0 gradients, 109.9 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 25/25 [00:10<00:00,  2.28it/s]\n",
            "                   all        199        285      0.871      0.719      0.813      0.549\n",
            "Results saved to \u001b[1mruns/train/Model11\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5n.pt --batch 8 --name Model --img 640 --epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHK8GqWk0taB",
        "outputId": "729f8eac-20a6-4b8c-9148-fffa8c8ab600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 17.6MB/s]\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5n.pt to yolov5n.pt...\n",
            "100% 3.87M/3.87M [00:00<00:00, 18.2MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1      8118  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "Model summary: 214 layers, 1765270 parameters, 1765270 gradients, 4.2 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5n.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model12/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model12\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/4     0.908G    0.09577    0.03305          0         13        640: 100% 100/100 [02:40<00:00,  1.60s/it]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:04<00:00,  3.21it/s]\n",
            "                   all        199        285      0.154      0.186     0.0947      0.029\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/4      1.55G    0.06739    0.03003          0         22        640: 100% 100/100 [00:29<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.79it/s]\n",
            "                   all        199        285      0.241      0.359      0.199     0.0772\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/4      1.55G    0.05853    0.02756          0         21        640: 100% 100/100 [00:29<00:00,  3.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  4.26it/s]\n",
            "                   all        199        285      0.667      0.488      0.557      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/4      1.55G    0.04932    0.02558          0         13        640: 100% 100/100 [00:29<00:00,  3.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.46it/s]\n",
            "                   all        199        285      0.692      0.632      0.684      0.334\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/4      1.55G     0.0466    0.02501          0         17        640: 100% 100/100 [00:29<00:00,  3.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.56it/s]\n",
            "                   all        199        285      0.668      0.635      0.668      0.321\n",
            "\n",
            "5 epochs completed in 0.082 hours.\n",
            "Optimizer stripped from runs/train/Model12/weights/last.pt, 3.9MB\n",
            "Optimizer stripped from runs/train/Model12/weights/best.pt, 3.9MB\n",
            "\n",
            "Validating runs/train/Model12/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.62it/s]\n",
            "                   all        199        285      0.688      0.635      0.684      0.335\n",
            "Results saved to \u001b[1mruns/train/Model12\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --data data.yaml --weights yolov5n.pt --batch 8 --name Model --img 640 --epochs 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdfIHAN63omz",
        "outputId": "d52402a1-9eb9-41eb-8f05-659e52ba7b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5n.pt, cfg=, data=data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=10, batch_size=8, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=Model, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0m⚠️ YOLOv5 is out of date by 4 commits. Use `git pull` or `git clone https://github.com/ultralytics/yolov5` to update.\n",
            "fatal: cannot change to '/content/drive/MyDrive/Polyp': No such file or directory\n",
            "YOLOv5 🚀 2022-12-26 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      1760  models.common.Conv                      [3, 16, 6, 2, 2]              \n",
            "  1                -1  1      4672  models.common.Conv                      [16, 32, 3, 2]                \n",
            "  2                -1  1      4800  models.common.C3                        [32, 32, 1]                   \n",
            "  3                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  4                -1  2     29184  models.common.C3                        [64, 64, 2]                   \n",
            "  5                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  6                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
            "  7                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  8                -1  1    296448  models.common.C3                        [256, 256, 1]                 \n",
            "  9                -1  1    164608  models.common.SPPF                      [256, 256, 5]                 \n",
            " 10                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 14                -1  1      8320  models.common.Conv                      [128, 64, 1, 1]               \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     22912  models.common.C3                        [128, 64, 1, False]           \n",
            " 18                -1  1     36992  models.common.Conv                      [64, 64, 3, 2]                \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1     74496  models.common.C3                        [128, 128, 1, False]          \n",
            " 21                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 24      [17, 20, 23]  1      8118  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [64, 128, 256]]\n",
            "Model summary: 214 layers, 1765270 parameters, 1765270 gradients, 4.2 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5n.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/train.cache... 798 images, 0 backgrounds, 0 corrupt: 100% 798/798 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Polyp Detection/dataset/test.cache... 199 images, 0 backgrounds, 0 corrupt: 100% 199/199 [00:00<?, ?it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.62 anchors/target, 0.991 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n",
            "Plotting labels to runs/train/Model13/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/Model13\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        0/9     0.988G    0.09577    0.03305          0         13        640: 100% 100/100 [00:33<00:00,  3.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  4.19it/s]\n",
            "                   all        199        285      0.154      0.186     0.0947      0.029\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        1/9      1.63G    0.06747    0.02998          0         22        640: 100% 100/100 [00:30<00:00,  3.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.86it/s]\n",
            "                   all        199        285       0.31      0.288      0.198     0.0834\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        2/9      1.63G    0.05853    0.02708          0         21        640: 100% 100/100 [00:30<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.85it/s]\n",
            "                   all        199        285      0.366      0.449      0.344     0.0926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        3/9      1.63G    0.05205    0.02479          0         13        640: 100% 100/100 [00:30<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.63it/s]\n",
            "                   all        199        285      0.682      0.533      0.612      0.249\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        4/9      1.63G    0.04728    0.02468          0         17        640: 100% 100/100 [00:30<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.81it/s]\n",
            "                   all        199        285      0.721      0.579      0.654      0.328\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        5/9      1.63G    0.04307    0.02355          0         17        640: 100% 100/100 [00:29<00:00,  3.35it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.73it/s]\n",
            "                   all        199        285      0.666      0.602       0.67      0.379\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        6/9      1.63G    0.04096    0.02292          0         11        640: 100% 100/100 [00:30<00:00,  3.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.51it/s]\n",
            "                   all        199        285      0.706      0.702      0.747       0.42\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        7/9      1.63G    0.03866    0.02358          0         14        640: 100% 100/100 [00:30<00:00,  3.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:05<00:00,  2.40it/s]\n",
            "                   all        199        285      0.699      0.718      0.763      0.455\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        8/9      1.63G    0.03684    0.02348          0         18        640: 100% 100/100 [00:30<00:00,  3.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.64it/s]\n",
            "                   all        199        285       0.77      0.705      0.792      0.477\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "        9/9      1.63G    0.03507    0.02114          0         12        640: 100% 100/100 [00:29<00:00,  3.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:02<00:00,  4.55it/s]\n",
            "                   all        199        285        0.8      0.667      0.789      0.487\n",
            "\n",
            "10 epochs completed in 0.095 hours.\n",
            "Optimizer stripped from runs/train/Model13/weights/last.pt, 3.9MB\n",
            "Optimizer stripped from runs/train/Model13/weights/best.pt, 3.9MB\n",
            "\n",
            "Validating runs/train/Model13/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 1760518 parameters, 0 gradients, 4.1 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 13/13 [00:03<00:00,  3.75it/s]\n",
            "                   all        199        285      0.801      0.665      0.789      0.488\n",
            "Results saved to \u001b[1mruns/train/Model13\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}